{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqzfaZFEE_Rm"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import dataset, dataloader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os, json\n",
    "import copy\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "from collections import Counter, OrderedDict\n",
    "import re\n",
    "import requests\n",
    "import tarfile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_FYDlNMWIXA"
   },
   "outputs": [],
   "source": [
    "data_dir = 'data2'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSQOuCnkPW8X"
   },
   "source": [
    "Data prep for pets data following this [notebook](https://colab.research.google.com/github/akashmehra/blog/blob/fastbook/lessons/_notebooks/2021-07-20-pets_classifier.ipynb#scrollTo=ekNHMAUtklXS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELmSWsujIa9L"
   },
   "outputs": [],
   "source": [
    "# normalize images with the following transform mean and std\n",
    "mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop((224,224)),     # resize image\n",
    "                                      transforms.RandomHorizontalFlip(), # augment\n",
    "                                      transforms.ToTensor(),    # change to Tensor\n",
    "                                      transforms.Normalize(mean = mean, \n",
    "                                                            std = std)  ])# normalize with mean & std from docs\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([transforms.Resize((224,224)),               # resize image\n",
    "                                    transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(),    # change to Tensor\n",
    "                                    transforms.Normalize(mean = mean, \n",
    "                                                         std = std)  ])# normalize with mean & std from docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zynUIZNOVZ2v"
   },
   "outputs": [],
   "source": [
    "def fetch_data(url, data_dir, download=False):\n",
    "    if download:\n",
    "        response = requests.get(url, stream=True)\n",
    "        file = tarfile.open(fileobj=response.raw, mode=\"r|gz\")\n",
    "        file.extractall(path=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DANchqQQVZ0h"
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "pets_url = 'https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet.tgz'\n",
    "#data_dir = os.path.join('drive', 'MyDrive', 'pets_data')\n",
    "base_img_dir = os.path.join(data_dir, 'oxford-iiit-pet', 'images')\n",
    "fetch_data(pets_url, data_dir, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ezUKult8VZwB"
   },
   "outputs": [],
   "source": [
    "class RegexLabelExtractor():\n",
    "    def __init__(self, pattern):\n",
    "        self.pattern = pattern\n",
    "        self._names = []\n",
    "    \n",
    "    def __call__(self, iterable):\n",
    "        return [re.findall(self.pattern, value)[0] for value in iterable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5IYme6_VZtw"
   },
   "outputs": [],
   "source": [
    "class LabelManager():\n",
    "    def __init__(self, labels):\n",
    "        self._label_to_idx = OrderedDict()    \n",
    "        for label in labels:\n",
    "            if label not in self._label_to_idx:\n",
    "                self._label_to_idx[label] = len(self._label_to_idx)\n",
    "        self._idx_to_label = {v:k for k,v in self._label_to_idx.items()}\n",
    "    \n",
    "    @property\n",
    "    def keys(self):\n",
    "        return list(self._label_to_idx.keys())\n",
    "    \n",
    "    def id_for_label(self, label):\n",
    "        return self._label_to_idx[label]\n",
    "    \n",
    "    def label_for_id(self, idx):\n",
    "        return self._idx_to_label[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._label_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvQLG3JwVZrN"
   },
   "outputs": [],
   "source": [
    "class Splitter():\n",
    "    def __init__(self, valid_pct=0.2, seed = None):\n",
    "        self.seed = seed\n",
    "        self.valid_pct = valid_pct\n",
    "    \n",
    "    def __call__(self, dataset):\n",
    "        return train_test_split(dataset, test_size=self.valid_pct, random_state=np.random.RandomState(self.seed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPPYf4KoVZoY"
   },
   "outputs": [],
   "source": [
    "class PetsDataset(dataset.Dataset):\n",
    "    def __init__(self, data, tfms=None):\n",
    "        super(PetsDataset, self).__init__()\n",
    "        self.data = data\n",
    "        self.transforms = tfms\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = Image.open(self.data[idx][0])\n",
    "        if X.mode != 'RGB':\n",
    "            X = X.convert('RGB')\n",
    "        y = self.data[idx][1]\n",
    "        if self.transforms:\n",
    "            X = self.transforms(X)\n",
    "        return (X, y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IG2ZlJuVZfh"
   },
   "outputs": [],
   "source": [
    "class DatasetManager():\n",
    "    \n",
    "    def __init__(self, base_dir, paths, label_extractor, tfms=None, valid_pct=0.2, seed=None):\n",
    "        self._labels = label_extractor(paths)\n",
    "        self.tfms = tfms\n",
    "        self._label_manager = LabelManager(self._labels)\n",
    "        self._label_ids = [self.label_manager.id_for_label(label) for label in self._labels]\n",
    "\n",
    "        self.abs_paths = [os.path.join(base_dir, path) for path in paths]\n",
    "        self.train_data, self.valid_data = Splitter(valid_pct=valid_pct, seed=seed)(list(zip(self.abs_paths, self._label_ids)))\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def label_manager(self):\n",
    "        return self._label_manager\n",
    "    \n",
    "    @property\n",
    "    def train_dataset(self):\n",
    "        return PetsDataset(self.train_data, tfms=self.tfms)\n",
    "\n",
    "    @property\n",
    "    def valid_dataset(self):    \n",
    "        return PetsDataset(self.valid_data, tfms=self.tfms)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fha5Zd0SVkPA"
   },
   "outputs": [],
   "source": [
    "paths = [path for path in sorted(os.listdir(base_img_dir)) if path.endswith('.jpg')]\n",
    "pattern = '(.+)_\\d+.jpg$'\n",
    "regex_label_extractor = RegexLabelExtractor(pattern)\n",
    "dataset_manager = DatasetManager(base_img_dir, paths, regex_label_extractor, \n",
    "                                 tfms=val_transform, \n",
    "                                 seed=42)\n",
    "train_dataset = dataset_manager.train_dataset\n",
    "valid_dataset = dataset_manager.valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1664395008949,
     "user": {
      "displayName": "Hyland DS",
      "userId": "14372689090472009900"
     },
     "user_tz": 240
    },
    "id": "XDL8AhiTVkLu",
    "outputId": "a83619b2-92b4-4759-cd91-1e2dae74c290"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-005577e0-51a0-4037-8dc0-992fc78ea510\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abyssinian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bengal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Birman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bombay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>British_Shorthair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Egyptian_Mau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Maine_Coon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Persian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ragdoll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Russian_Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Siamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sphynx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>american_bulldog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>american_pit_bull_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>basset_hound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>beagle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>boxer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>chihuahua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>english_cocker_spaniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>english_setter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>german_shorthaired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>great_pyrenees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>havanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>japanese_chin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>keeshond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>leonberger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>miniature_pinscher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>newfoundland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pomeranian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>pug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>saint_bernard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>samoyed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>scottish_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>shiba_inu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>staffordshire_bull_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>wheaten_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>yorkshire_terrier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-005577e0-51a0-4037-8dc0-992fc78ea510')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-005577e0-51a0-4037-8dc0-992fc78ea510 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-005577e0-51a0-4037-8dc0-992fc78ea510');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                    label_name\n",
       "0                   Abyssinian\n",
       "1                       Bengal\n",
       "2                       Birman\n",
       "3                       Bombay\n",
       "4            British_Shorthair\n",
       "5                 Egyptian_Mau\n",
       "6                   Maine_Coon\n",
       "7                      Persian\n",
       "8                      Ragdoll\n",
       "9                 Russian_Blue\n",
       "10                     Siamese\n",
       "11                      Sphynx\n",
       "12            american_bulldog\n",
       "13   american_pit_bull_terrier\n",
       "14                basset_hound\n",
       "15                      beagle\n",
       "16                       boxer\n",
       "17                   chihuahua\n",
       "18      english_cocker_spaniel\n",
       "19              english_setter\n",
       "20          german_shorthaired\n",
       "21              great_pyrenees\n",
       "22                    havanese\n",
       "23               japanese_chin\n",
       "24                    keeshond\n",
       "25                  leonberger\n",
       "26          miniature_pinscher\n",
       "27                newfoundland\n",
       "28                  pomeranian\n",
       "29                         pug\n",
       "30               saint_bernard\n",
       "31                     samoyed\n",
       "32            scottish_terrier\n",
       "33                   shiba_inu\n",
       "34  staffordshire_bull_terrier\n",
       "35             wheaten_terrier\n",
       "36           yorkshire_terrier"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse-output\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(dataset_manager.label_manager.keys, columns=['label_name'])\n",
    "df.head(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_KABKpUVkIc"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def plot_one_batch(batch, max_images=9):\n",
    "    nrows = int(math.sqrt(max_images))\n",
    "    ncols = int(math.sqrt(max_images))\n",
    "    if nrows * ncols != max_images:\n",
    "        nrows = (max_images + ncols - 1) // ncols \n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 10))\n",
    "    X,Y = next(batch)\n",
    "    for idx, x in enumerate(X[:max_images]):\n",
    "        y = Y[idx]\n",
    "        ax.ravel()[idx].imshow(transforms.ToPILImage()(x))\n",
    "        ax.ravel()[idx].set_title(f'{y}/{dataset_manager.label_manager.label_for_id(y.item())}')\n",
    "        ax.ravel()[idx].set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "executionInfo": {
     "elapsed": 7226,
     "status": "ok",
     "timestamp": 1664395025247,
     "user": {
      "displayName": "Hyland DS",
      "userId": "14372689090472009900"
     },
     "user_tz": 240
    },
    "id": "yorG9PeuVkFs",
    "outputId": "12d6cd3a-8141-4c2c-fabe-5b47317e8ea8"
   },
   "outputs": [],
   "source": [
    "# these will terrible becuase I didn't unnormalize photos before plotting\n",
    "def generate_one_batch(dl):\n",
    "    for batch in dl:\n",
    "        yield batch\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
    "plot_one_batch(generate_one_batch(train_dl), max_images=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1664395033286,
     "user": {
      "displayName": "Hyland DS",
      "userId": "14372689090472009900"
     },
     "user_tz": 240
    },
    "id": "m2_mcm_KVy-h",
    "outputId": "211cd2b8-c39e-4a66-c9fb-4b8b8474dc15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5912"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1664395037030,
     "user": {
      "displayName": "Hyland DS",
      "userId": "14372689090472009900"
     },
     "user_tz": 240
    },
    "id": "uJJTsBdEIdq5",
    "outputId": "261f3f53-342c-4fd8-bfba-c82b77ff7c17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 5\n",
    "feature_extract = False\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ex4Ei9dHIeai"
   },
   "outputs": [],
   "source": [
    "# Create training and validation datasets\n",
    "image_datasets = {\"train\": train_dataset,\n",
    "                  \"val\": valid_dataset}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1664395041877,
     "user": {
      "displayName": "Hyland DS",
      "userId": "14372689090472009900"
     },
     "user_tz": 240
    },
    "id": "ZXLm9vBFLuEA",
    "outputId": "c5994752-f7f3-47e7-b237-3c1f714ceef6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <__main__.PetsDataset at 0x7fe335cbc410>,\n",
       " 'val': <__main__.PetsDataset at 0x7fe3353d6910>}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUUFzlNYNR-r"
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 601,
     "status": "ok",
     "timestamp": 1664395046619,
     "user": {
      "displayName": "Hyland DS",
      "userId": "14372689090472009900"
     },
     "user_tz": 240
    },
    "id": "1dE4oc9AIkqW",
    "outputId": "0711efdd-4519-4ef2-a0c2-bc562dce437b",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet34(pretrained=True)\n",
    "set_parameter_requires_grad(model_ft, False)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 37)   # we have 37 classes\n",
    "# # re-initialize random weights & biases for fc layer\n",
    "# nn.init.kaiming_normal_(model.fc.weight) \n",
    "# nn.init.zeros_(model.fc.bias)\n",
    "model_ft.to(device)\n",
    "\n",
    "\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEyz4c77IsNY"
   },
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html#run-training-and-validation-step\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device) \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs , labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZRFvPuDZYqK"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params_to_update, lr = 0.0001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1587903,
     "status": "ok",
     "timestamp": 1664396649107,
     "user": {
      "displayName": "Hyland DS",
      "userId": "14372689090472009900"
     },
     "user_tz": 240
    },
    "id": "sIwOwDUfaPjt",
    "outputId": "6abedb6b-75ee-4aad-cfcc-b669b1955f43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/17\n",
      "----------\n",
      "train Loss: 3.3576 Acc: 0.1563\n",
      "val Loss: 2.8563 Acc: 0.3870\n",
      "\n",
      "Epoch 1/17\n",
      "----------\n",
      "train Loss: 2.4686 Acc: 0.5438\n",
      "val Loss: 2.0308 Acc: 0.6996\n",
      "\n",
      "Epoch 2/17\n",
      "----------\n",
      "train Loss: 1.7650 Acc: 0.7556\n",
      "val Loss: 1.4433 Acc: 0.8153\n",
      "\n",
      "Epoch 3/17\n",
      "----------\n",
      "train Loss: 1.3039 Acc: 0.8353\n",
      "val Loss: 1.0785 Acc: 0.8593\n",
      "\n",
      "Epoch 4/17\n",
      "----------\n",
      "train Loss: 1.0217 Acc: 0.8596\n",
      "val Loss: 0.8539 Acc: 0.8796\n",
      "\n",
      "Epoch 5/17\n",
      "----------\n",
      "train Loss: 0.8321 Acc: 0.8813\n",
      "val Loss: 0.6988 Acc: 0.8951\n",
      "\n",
      "Epoch 6/17\n",
      "----------\n",
      "train Loss: 0.7146 Acc: 0.8928\n",
      "val Loss: 0.6116 Acc: 0.9039\n",
      "\n",
      "Epoch 7/17\n",
      "----------\n",
      "train Loss: 0.6185 Acc: 0.8970\n",
      "val Loss: 0.5370 Acc: 0.9161\n",
      "\n",
      "Epoch 8/17\n",
      "----------\n",
      "train Loss: 0.5469 Acc: 0.9073\n",
      "val Loss: 0.4816 Acc: 0.9147\n",
      "\n",
      "Epoch 9/17\n",
      "----------\n",
      "train Loss: 0.4898 Acc: 0.9198\n",
      "val Loss: 0.4413 Acc: 0.9168\n",
      "\n",
      "Epoch 10/17\n",
      "----------\n",
      "train Loss: 0.4498 Acc: 0.9222\n",
      "val Loss: 0.4054 Acc: 0.9242\n",
      "\n",
      "Epoch 11/17\n",
      "----------\n",
      "train Loss: 0.4022 Acc: 0.9285\n",
      "val Loss: 0.3794 Acc: 0.9235\n",
      "\n",
      "Epoch 12/17\n",
      "----------\n",
      "train Loss: 0.3768 Acc: 0.9332\n",
      "val Loss: 0.3613 Acc: 0.9269\n",
      "\n",
      "Epoch 13/17\n",
      "----------\n",
      "train Loss: 0.3489 Acc: 0.9350\n",
      "val Loss: 0.3393 Acc: 0.9283\n",
      "\n",
      "Epoch 14/17\n",
      "----------\n",
      "train Loss: 0.3192 Acc: 0.9442\n",
      "val Loss: 0.3232 Acc: 0.9296\n",
      "\n",
      "Epoch 15/17\n",
      "----------\n",
      "train Loss: 0.3034 Acc: 0.9452\n",
      "val Loss: 0.3129 Acc: 0.9269\n",
      "\n",
      "Epoch 16/17\n",
      "----------\n",
      "train Loss: 0.2852 Acc: 0.9516\n",
      "val Loss: 0.2998 Acc: 0.9323\n",
      "\n",
      "Epoch 17/17\n",
      "----------\n",
      "train Loss: 0.2610 Acc: 0.9569\n",
      "val Loss: 0.2908 Acc: 0.9310\n",
      "\n",
      "Training complete in 26m 28s\n",
      "Best val Acc: 0.932341\n"
     ]
    }
   ],
   "source": [
    "model_ft2, hist2 = train_model(model_ft, dataloaders_dict, criterion, optimizer, num_epochs = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ug7wPHTvZYfM"
   },
   "outputs": [],
   "source": [
    "torch.save(model_ft2.state_dict(), '/content/drive/MyDrive/model_pets.pt')\n",
    "# torch.save(model_ft2.state_dict(), '/content/drive/MyDrive/model_2SGD_pets.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frP0DJDiuad1"
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPlpFbRdXD2ALGGA2VU/nkD",
   "collapsed_sections": [],
   "mount_file_id": "1hF52WzmM6CI2J9YFyAJ-8mmc4elQp9C0",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
